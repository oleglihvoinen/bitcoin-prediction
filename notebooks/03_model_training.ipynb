{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Price Prediction - Model Training\n",
    "\n",
    "This notebook trains and evaluates machine learning models for Bitcoin price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the project root to Python path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from config.config import DATA_CONFIG, FEATURE_CONFIG, MODEL_CONFIG, LSTM_CONFIG, RF_CONFIG, PATHS\n",
    "from utils.data_loader import BitcoinDataLoader\n",
    "from utils.feature_engineering import FeatureEngineer\n",
    "from models.random_forest import BitcoinRandomForest\n",
    "from models.lstm_model import BitcoinLSTM\n",
    "from models.model_evaluation import ModelEvaluator\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Feature-Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with features\n",
    "try:\n",
    "    # Try to load pre-processed features\n",
    "    df_features = pd.read_csv('../data/bitcoin_features.csv', index_col='date', parse_dates=True)\n",
    "    print(\"‚úÖ Loaded pre-processed features from file\")\n",
    "except:\n",
    "    # Generate features from scratch\n",
    "    print(\"üîÑ Generating features from scratch...\")\n",
    "    data_loader = BitcoinDataLoader(DATA_CONFIG)\n",
    "    df = data_loader.load_data()\n",
    "    feature_engineer = FeatureEngineer(FEATURE_CONFIG)\n",
    "    df_features = feature_engineer.add_technical_indicators(df)\n",
    "\n",
    "print(\"üìä Data Shape:\", df_features.shape)\n",
    "print(\"üéØ Target variable present:\", 'target' in df_features.columns)\n",
    "\n",
    "# Show basic info\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target distribution\n",
    "if 'target' in df_features.columns:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df_features['target'], bins=50, alpha=0.7, color='skyblue')\n",
    "    plt.title('Target Variable Distribution', fontweight='bold')\n",
    "    plt.xlabel('Target (Price Change %)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Time series of target\n",
    "    plt.plot(df_features.index, df_features['target'], alpha=0.7)\n",
    "    plt.title('Target Variable Over Time', fontweight='bold')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Target (Price Change %)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìà Target Statistics:\")\n",
    "    print(df_features['target'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üå≤ Training Random Forest Model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize and train Random Forest\n",
    "rf_model = BitcoinRandomForest({**MODEL_CONFIG, **RF_CONFIG})\n",
    "rf_metrics, rf_y_test, rf_y_pred = rf_model.train(df_features)\n",
    "\n",
    "print(\"\\n‚úÖ Random Forest Training Complete!\")\n",
    "print(\"üìä Performance Metrics:\")\n",
    "for metric, value in rf_metrics.items():\n",
    "    print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "\n",
    "# Show feature importance\n",
    "if hasattr(rf_model, 'feature_importance') and rf_model.feature_importance is not None:\n",
    "    print(f\"\\nüîù Top 10 Most Important Features:\")\n",
    "    top_features = rf_model.feature_importance.head(10)\n",
    "    for _, row in top_features.iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüß† Training LSTM Model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize and train LSTM\n",
    "lstm_model = BitcoinLSTM({**MODEL_CONFIG, **LSTM_CONFIG})\n",
    "lstm_metrics, lstm_history, lstm_y_test, lstm_y_pred = lstm_model.train(df_features)\n",
    "\n",
    "print(\"\\n‚úÖ LSTM Training Complete!\")\n",
    "print(\"üìä Performance Metrics:\")\n",
    "for metric, value in lstm_metrics.items():\n",
    "    print(f\"  {metric.upper()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Model Comparison\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluator(PATHS['plots_dir'])\n",
    "\n",
    "# Compare models\n",
    "models_metrics = {\n",
    "    'Random Forest': rf_metrics,\n",
    "    'LSTM': lstm_metrics\n",
    "}\n",
    "\n",
    "metrics_df = evaluator.compare_models(models_metrics)\n",
    "\n",
    "# Plot predictions comparison\n",
    "if rf_y_test is not None and lstm_y_test is not None:\n",
    "    evaluator.plot_predictions_comparison(rf_y_test, rf_y_pred, lstm_y_test, lstm_y_pred)\n",
    "\n",
    "# Plot feature importance\n",
    "if hasattr(rf_model, 'feature_importance') and rf_model.feature_importance is not None:\n",
    "    evaluator.plot_feature_importance(rf_model.feature_importance)\n",
    "\n",
    "# Plot training history for LSTM\n",
    "if lstm_history is not None:\n",
    "    evaluator.plot_training_history(lstm_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed performance analysis\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 1. Prediction vs Actual (Random Forest)\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.scatter(rf_y_test, rf_y_pred, alpha=0.6, color='blue')\n",
    "plt.plot([rf_y_test.min(), rf_y_test.max()], [rf_y_test.min(), rf_y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Random Forest: Actual vs Predicted', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Prediction vs Actual (LSTM)\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.scatter(lstm_y_test, lstm_y_pred, alpha=0.6, color='green')\n",
    "plt.plot([lstm_y_test.min(), lstm_y_test.max()], [lstm_y_test.min(), lstm_y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('LSTM: Actual vs Predicted', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals (Random Forest)\n",
    "plt.subplot(2, 3, 3)\n",
    "rf_residuals = rf_y_test - rf_y_pred\n",
    "plt.scatter(rf_y_pred, rf_residuals, alpha=0.6, color='blue')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Random Forest: Residuals', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuals (LSTM)\n",
    "plt.subplot(2, 3, 4)\n",
    "lstm_residuals = lstm_y_test - lstm_y_pred\n",
    "plt.scatter(lstm_y_pred, lstm_residuals, alpha=0.5, color='green')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('LSTM: Residuals', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Error Distribution\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.hist(rf_residuals, bins=30, alpha=0.7, color='blue', label='Random Forest', density=True)\n",
    "plt.hist(lstm_residuals, bins=30, alpha=0.7, color='green', label='LSTM', density=True)\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Error Distribution', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Time Series of Predictions (first 100 points)\n",
    "plt.subplot(2, 3, 6)\n",
    "n_points = min(100, len(rf_y_test))\n",
    "indices = range(n_points)\n",
    "plt.plot(indices, rf_y_test[:n_points], label='Actual', color='black', linewidth=2)\n",
    "plt.plot(indices, rf_y_pred[:n_points], label='RF Predicted', color='blue', linestyle='--')\n",
    "plt.plot(indices, lstm_y_pred[:n_points], label='LSTM Predicted', color='green', linestyle='--')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Target Value')\n",
    "plt.title('Predictions Over Time', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üíæ Saving Trained Models...\")\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(PATHS['models_dir'], exist_ok=True)\n",
    "\n",
    "# Save Random Forest model\n",
    "rf_model_path = os.path.join(PATHS['models_dir'], 'random_forest_model.joblib')\n",
    "rf_model.save_model(rf_model_path)\n",
    "\n",
    "# Save LSTM model\n",
    "lstm_model_path = os.path.join(PATHS['models_dir'], 'lstm_model.h5')\n",
    "lstm_scaler_path = os.path.join(PATHS['models_dir'], 'lstm_scaler.joblib')\n",
    "lstm_model.save_model(lstm_model_path, lstm_scaler_path)\n",
    "\n",
    "print(\"‚úÖ Models saved successfully!\")\n",
    "print(f\"üìÅ Models location: {PATHS['models_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create performance comparison table\n",
    "performance_data = []\n",
    "for model_name, metrics in models_metrics.items():\n",
    "    performance_data.append({\n",
    "        'Model': model_name,\n",
    "        'MAE': f\"{metrics['mae']:.4f}%\",\n",
    "        'RMSE': f\"{metrics['rmse']:.4f}%\",\n",
    "        'R¬≤': f\"{metrics['r2']:.4f}\",\n",
    "        'MSE': f\"{metrics['mse']:.6f}\"\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "print(\"\\nüìä Performance Comparison:\")\n",
    "display(performance_df)\n",
    "\n",
    "# Determine best model\n",
    "best_model = max(models_metrics.items(), key=lambda x: x[1]['r2'])\n",
    "print(f\"\\nüèÜ Best Performing Model: {best_model[0]}\")\n",
    "print(f\"   R¬≤ Score: {best_model[1]['r2']:.4f}\")\n",
    "print(f\"   MAE: {best_model[1]['mae']:.4f}%\")\n",
    "\n",
    "# Key insights\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"‚Ä¢ LSTM generally performs better for time series data due to sequence learning\")\n",
    "print(\"‚Ä¢ Random Forest provides good interpretability through feature importance\")\n",
    "print(\"‚Ä¢ Both models capture meaningful patterns in Bitcoin price movements\")\n",
    "print(\"‚Ä¢ Model performance is affected by market volatility regimes\")\n",
    "\n",
    "print(\"\\n‚úÖ Model training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Model Deployment**: Use the saved models for real-time predictions\n",
    "2. **Hyperparameter Tuning**: Further optimize model parameters\n",
    "3. **Ensemble Methods**: Combine both models for improved performance\n",
    "4. **Feature Engineering**: Experiment with additional features\n",
    "5. **Model Monitoring**: Set up performance tracking over time\n",
    "\n",
    "The trained models are now ready for making Bitcoin price predictions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}